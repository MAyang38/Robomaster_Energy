2019,9月中旬-2019，10,11

已完成
01. 完成灯条框选；
02. 灯条匹配；
03. SVM识别

下一步目标
01. PNP测距/三角测距
02. 改旋转矩形为旋转椭圆
03. 尝试将deltaCV加入工程
04. 进一步熟悉libSVM，添加负样本（重新制作样本训练集）
05. 将19年部分灯条判断条件和灯条匹配条件添加进工程
06. 加入条件编译，方便调试维护
07. 加入不同颜色模式
08. 加入19年单灯条识别
09. 重构工程结构（重新学习CmakeList编写）
10. 视野开阔
11. 重新了解透视变换
12. 添加hog+SVM判断装甲板


2019/10/13
已完成
1. 集成19年灯条判断条件
2. 添加部分条件编译
3. 改为旋转椭圆
4. 匹配条件
5.
添加目标
1. 在之前的程序中发现部分框选的灯条或者装甲板会超出图像的界限，之前采用的是if条件判断跳过这部分超出范围的的roi；
查看19年代码后可以将ROI进行收缩，添加矩形收束函数；
2. 添加命名空间，yml参数表，将颜色条件改条件编译为参数改变；

2019/10/14  周一
已完成
01. 进一步完善条件编译
02. 在原有破烂训练集的基础上添加一些破烂样本，贴上标签为0，相当于二分类中的负样本，训练出来后在装甲板识别中加上了SVM判别步骤，
进一步减少了误识别，

待完成及添加目标
01. SVM模型中添加hog特征，重制训练集
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
04. 尝试将deltaCV加入工程
05. 重制工程（重新了解cmakelist编写）
06. 透视变换
07. deltaCV
08. 旋转矩形约束
09. 追踪
10. 熟悉看懂19年框选机制

2019/10/15 周二
已完成
1. 无
2. 主要看规则

待完成及添加目标
01. SVM模型中添加hog特征，重制训练集
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
04. 尝试将deltaCV加入工程
05. 重制工程（重新了解cmakelist编写）
06. 透视变换
07. deltaCV
08. 旋转矩形约束
09. 追踪
10. 熟悉看懂19年框选机制
11. 看规则

2019/10/16o 周三
已完成
1. 再添加1灯条匹配条件(灯条起点高度差)
添加/待完成



2019/10/17  周四
已完成
无


2019/10/18  周五
已完成
1. 改变框选方式，模仿19/18年
2. 在新的框选方式基础上对roi添加透视变换，在此基础上重制训练集后识别效率应该更高，获得的ROI“离散性”会更小
3. 添加边界点约束，防止点出界而导致程序崩溃
待完成及添加目标
01. SVM模型中添加hog特征<->重制训练集
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
04. 尝试将deltaCV加入工程
05. 重制工程（重新了解cmakelist编写）
06. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
07. 对ROI区域进行优化，修复数字撕裂区域×
08. single_blob
09. 尝试修复不能使用大华驱动问题或者将此代码置于一nuc上;

2019/10/19 周六
已完成
1. 添加对roi的形态学处理
2. 在昨日新的框选方法基础上略作修改尝试在ROI中去掉灯条，但灯条的灯光仍会有部分影响
3. 大华sdk

待完成及添加目标
01. SVM模型中添加hog特征<->重制训练集
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
04. 尝试将deltaCV加入工程
05. 重制工程（重新了解cmakelist编写）
06. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
07. single_blob

2019/10/20 周日
已完成
1. SVM分类器加入hog特征
2. 在新的分类器基础上重制训练集，可能还需要增集

待完成及添加目标
01. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
02. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
03. 尝试将deltaCV加入工程
04. 重制工程（重新了解cmakelist编写）
05. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
06. single_blob
07. 决策
08. 多次制作训练集，每一次将上一批误识别样本加入负样本集

# armor_02
对第一版自瞄代码进行整理，重新调整工程结构目录

上接上版代码WORK_LOGS

2019/10/20 周日
已完成
1. SVM分类器加入hog特征
2. 在新的分类器基础上重制训练集，可能还需要增集

待完成及添加目标
01. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
02. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
03. 尝试将deltaCV加入工程
04. 重制工程（重新了解cmakelist编写）
05. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
06. single_blob
07. 决策
08. 多次制作训练集，每一次将上一批误识别样本加入负样本集


2019/10/21 周一
已完成
1. 初步完成2.0版本结构，完成构思
2. 新增灯条对类，取代直接有的装甲板类（因为原先装甲板类并未经过SVM分类，即有可能是id=0的装甲板，即非装甲板）
3. 构思新增单灯条对类
4. 添加命名空间，专门用于存放参数，预计下一步将这些参数值置于一yml文件上
5. 采用hpp文件存放功能函数


待完成及添加目标
01. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
02. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
03. 尝试将deltaCV加入工程
04. 重制工程（重新了解cmakelist编写）
05. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
06. single_blob
07. 决策
08. 多次制作训练集，每一次将上一批误识别样本加入负样本集
09. 完成单灯条对类
10. 完成ArmorLibs.hpp
11. 初始化函数
12. 重新检查工程中有关角度的计算

2019/10/22 周二
已完成
1. 基本完成功能函数编写
2. 结合自己初步理解与想法添加粗糙的单灯条识别（等进一步19年看懂在进行结合，改进）
3. 将主体功能部分添加为两个进程，分别用于测试与正式使用（无实际意义，练习用）

待完成及添加目标
01. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
02. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
03. 尝试将deltaCV加入工程
04. 重制工程（重新了解cmakelist编写）
05. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
06. single_blob
07. 决策
08. 多次制作训练集，每一次将上一批误识别样本加入负样本集
09. 初始化函数（联动yml）
10. 重新检查工程中有关角度的计算

2019/10/23  周三
已完成
1. 工程整体重制完成，等待重制模型后debug
2. 初始化函数（联动yml）
3. 参数集中在一个yml文件上，添加命名空间，便与调试，装甲板颜色的改变方式有条件编译改为该yml参数
4. single_blob(待debug)

待完成即添加目标
01. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 尝试将deltaCV加入工程
04. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
05. 决策
06. 多次制作训练集，每一次将上一批误识别样本加入负样本集
07. 重新检查工程中有关角度的计算
08. degug
09. 添加展示相关功能

2019/10/24 周四
DONE
1. 重制debug完成
2. 添加一部分调用相机相关
3. show相关

TODO
01. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 尝试将deltaCV加入工程
04. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
05. 决策
06. 多次制作训练集，每一次将上一批误识别样本加入负样本集
07. 重新检查工程中有关角度的计算
08. 相机调用

2019/10/25  周五

NOTE
1. 大华SDK2.21版本的MVViewer文件夹名改为MVviewer，在参考以前的cmakelist文件时注意区分，否则无法调用相关的头文件，坑爹
2. 先暂时将timer库从cmakelist中去掉（无法找到）
3. shm 共享内存相关（share memory）

DONE
1. 完成部分相机工程的迁移（还未能对每一个环节了解）
2. 安装boost库
3. 好吧，就是没有取得实质性进展>>>>>>>>>。。。。。。

TODO
01. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
02. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
03. 尝试将deltaCV加入工程
04. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
05. 决策
06. 多次制作训练集，每一次将上一批误识别样本加入负样本集
07. 重新检查工程中有关角度的计算
08. 相机调用
09. 研究boost之共享内存，两进程间通信，de视频的boost bug


2019/10/26  周六`
NOTE
1. 调用相机时发现Subcriber找不到共享内存
2. boost::function<>
3. memcpy
4. 不要在虚拟环境下编译boost

DONE
01.调用相机成功
02. 研究boost之共享内存，两进程间通信，de视频的boost bug
03. 重制训练集完成

TODO
01. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
02. 了解角度结算
03. 端口数据传递
04. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
05. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。
06. 尝试将deltaCV加入工程
07. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
08. 决策
09. 新建工程的语法器始终报错，决定照着新工程的模样，将老工程改造，放弃新工程，反正新老工程差异不大，新工程起了让我重新熟悉cmakelist的作用，功勋卓著


2019/10/27  Sun

NOTE
01. 一个奇怪的现象，之几天运行程序时imshow会明显跟不上程序运行处理图片的速度，比PPT还卡，昨晚上突然又恢复正常了，不明原因
02. 变量名没注意一致，导致出错，内存访问错误

DONE
01. PNP测距，尝试了几种method，还是默认的迭代（false）效果最好,不要开true
02. 新建工程的语法器始终报错，决定照着新工程的模样，将老工程改造，放弃新工程，反正新老工程差异不大，新工程起了让我重新熟悉cmakelist的作用，功勋卓著
03. 决策

TODO
01. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
02. 了解角度结算
03. 端口数据传递
04. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
05. 学习pnp，进一步熟悉相机坐标系，像素坐标系，世界坐标系。。。(半完成状态)
06. 尝试将deltaCV加入工程
07. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
08. yaw，pitch转化


2019/10/28  Mon
NOTE
01. mat矩阵单元素访问很久未用，记不起来，matname.at<double/float/.....>(..,..)

DONE
01. 有PnP到yaw，pitch转化
02. 做了一个小博客做学习记录（好像费的时间有点多....）

TODO
01. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
02. 端口数据传递
03. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
04. 尝试将deltaCV加入工程
05. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
06. 如何从源头将图片变小
07. 考虑测距能不能做到更好


2019/10/29 Tue

NOTE
1. 昨晚上在利用了PnP解算出的旋转矩阵来估算物体的旋转角度后，发现效果并不是很理想，今天再看了去年的代码，发现没有使用解PnP得出旋转向量，而是根据一种自行设计的算法，于是打算用几何关系里来推算角度；
2. 根据刚看的相机成像原理，解算目标物的方向时，似乎不应该使用solvePnP的旋转向量来计算，而是根据图像坐标系求到物体在相机坐标系里的坐标点来计算方向，才是我们所求的点
3. 因为PnP测的距离难免不真确，故考虑其仅用来决策，在估算target的偏转角时考虑要求电控返回红外测距值来计算
4. 此版本Clion在更改函数返回类型时，注意应先更改声明，且保持实现处无效化，再更改，即不能有同名的不同返回类函数，否则卡死，之前的功夫也白费，之前的代码不保存，也可以养成随手ctrl+s的习惯
5. 调用数组时确保其中有元素，已多次犯同一错误
6. 注意新旧版本的SDK路径变化

DONE
1. 正确完成相机坐标系角度值计算，昨天的是瓜皮计算，sb计算，算的其实是相机相对于世界坐标系的位置


TODO
01. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
02. 端口数据传递（明天1）
03. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
04. 尝试将deltaCV加入工程
05. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)
06. 如何从源头将图片变小
07. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
08. 完善单灯条(明天2)
09. 优化测试界面，重新组织条件编译及测试信息输出
10. 改变帧数计算方式
11. 区域加速

2019/10/30 Wed

NOTE
1. 考虑到有的时候SVM失灵，那么在做预测算法时能否将条件放宽，只需要在预测的区域检测到灯条对或识别到数字(考虑到单灯条的情况)即可认为该区域为上一帧识别到的灯条（或者限制在一定帧数内）
2. 看串口通信时在UDP上浪费了大量的时间，下次注意搞清楚
3. 考虑到可以使用追踪算法，是否可以不使用区域加速

DONE
1. 完成串口通信
2. 修改单灯条思路，用类的思维来解决问题，不过似乎帧速暴降,不过检测的效果不错，不是太近的话感觉和用灯条对匹配效果差别不大

TODO
01. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
02. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
03. 尝试将deltaCV加入工程
04. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)(2)
05. 如何从源头将图片变小
06. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
07. 优化测试界面，重新组织条件编译及测试信息输出(1)
08. 改变帧数计算方式
09. 区域加速

2019/10/31 Thu

NOTE
1. 去年有人打了大符后忘记切换自瞄模式，可以考虑在ui加入模式提醒
2. 因为在循环里每次读取构造函数的参数可以快捷调参，但是会导致帧率大幅度降低，我还以为是单灯条的影响，另外此前构造得类都调用析构函数，不知是否会有影响，另外，可以考虑添加一部分内联函数
3. 不过经过测试发现单灯条还是会对帧率有影响，由原本80+变成现在40+;
4. 提高虚拟灯条长度要求后，帧率加快了，约60+（长度由10->30像素）；
5. 白天SVM检测不出数字，阳光太亮了,不过对ROI的形态学处理也需要改进
6. 考虑追踪算法与区域加速相结合，在识别到目标后，立即开始采用追踪算法，追踪算法失效后再采用区域加速，二者皆失效时采用全局检测
7. 我直接传原图给追踪算法进行追踪时，速度较慢，传给预测的图应当是一张二值图

DONE
1. 适当修改了测试界面更加便于调试
2. 初步对追踪有了想法，并完成一些初始工作
3. 改变帧数计算方式

TODO
01. 打算加入log系统
02. 为之前构造的类补充析构函数
03. 解决帧率过低问题
04. 查找适当修改变量类型，提炼公共子表达式，减少参数传递,添加const
05. 增加内联函数
06. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
07. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
08. 尝试将deltaCV加入工程
09. 添加追踪锁定(考虑到偶尔敌方灯条会不正常熄灭，很有必要)(2)
10. 如何从源头将图片变小
11. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
12. 重新组织条件编译及测试信息输出(1)
13. 区域加速

2019/11/01 FRI

NOTE
1. 傻吊的在if后面加分号，死循环的if下加break；
2. 考虑在图像获取进程对图片进行预处理，传回原图与预处理过的图，跟踪的对象放在预处理的图片上
3. 图像处理的速度足够快，那么即使未检测到也可在原来的预测的地方打上几帧，若在预设的帧数后仍未获得对象，再进行全局检测
4. 设立一个动态优先级，可以将上一帧在打的图片设为最高优先级,防止跟踪失效，则可以在（一定的帧数内）检测时优先检测这个id
5. 能否将追踪的区域设的小一点，然后直接将追踪区域送入SVM进行检测，未果再在追踪区域的放大区域再进行检测，还未检测到再跳过此帧，在下一帧进行全局检测


DONE
1. 追踪算法调用调节完成，可能提升帧速，可能降低帧速(ROI_REGIOB_SPEED_UP)
2. TRACKING_PRO;直接追踪，跳过检测，先判断后检测或者不检测，帧速再提升一点点
3. 由1,2适当提升帧速
4. 重新组织条件编译及测试信息输出(1)
5. 将上一帧目标设为最高优先级

TODO
01. 打算加入log系统
02. 为之前构造的类补充析构函数
03. (查找适当修改变量类型，提炼公共子表达式，减少参数传递,添加const)
04. 增加内联函数
05. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
06. 对roi形态学处理添加红蓝色分类,消除灯条灯光影响
07. 尝试将deltaCV加入工程
08. 有了追踪，但是锁定不是太好
09. 如何从源头将图片变小
10. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
11. 将预处理置于cam_node线程,同时传回二值图与原图
12. （长期任务）优化形态学处理过程
13. 写角度结算文档

2019/11/02  SAT

IDEA_NOTE
1. 因为追踪算法的MOSSE算法的速度足够的快，那么可以考虑增大ROIrect的面积，增大检测面积，提高成功率，减少全局检测次数，在整体上提升速率
2. 能否在cam_node_new添加ROI的形态学处理算法用于全图，传三张图过来，这边确定灯条对时直接在第三张图上框出来再进行透视变换，减少形态学处理,将追踪用于这张图是否会更好
3. 根据HSV得到亮度筛选图，对亮度筛选图进行RGB加权灰度化，再对自定义灰度图进行阈值化，最后进行一次腐蚀/膨胀

BUG_NOTE
1. ‘void (*)(cv::Mat&, cv::Mat&)’ is not a class, struct, or union type
        typedef typename F::result_type type;
        更改了相机的回调函数，给回调函数新增了一个参数imagePre后出现此问题
        解决方法：查询boost:bind用法后，添加_2参数，表示将函数第二个参数也调用
2. 将ArmorLibs加入cam_node线程，结果有许多函数显示未定义，因为我没有包含相关的文件；解决方法;将此文件去掉，直接将要用的函数复制过来;当然也可以把相关项都包进去，但是，都用不着，没必要
3. 在cam_node里将图片转换为灰度图不能用？看报错应该是参数的通道不对error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<1>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = (cv::impl::<unnamed>::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'，应该是因为先前已经将传出图片设为了三通道图片，无法再改为单通道图片?cv::Mat ThreshSrc=cv::Mat::zeros(src.size(), CV_8UC3);,嗯，是这个问题，，将threshSrc改为Temp，temp灰度化或二值化给另一张图后再传给传出图片
4. 成功在cam_node_new里进行预处理后，多传回了一张灰度图，原来在这边进行灰度化的时候，灰度图可能是roirect也可能是全图，现在灰度图仅能是全图，因此这边预处理要发生变化，分为搜寻状态与追踪状态，追踪状态用ROIrect，检索状态用全图

DONE
1. 将原图像的预处理迁入cam_node线程
2. 将对ROI的预处理也迁入cam_node线程，此时共从cam_node传出三张图，双方cpu占用约五五开(40%,40%)，帧率更快
3. 发现了一种十分适合追踪二值图的算法，配合done2，效果稳定，帧率不会有追踪彩图的卡顿感MedianFlow(一种光流算法),想试试基于深度学习的GOTURN跟踪器


TODO
01. 打算加入log系统
02. 为之前构造的类补充析构函数
03. (查找适当修改变量类型，提炼公共子表达式，减少参数传递,添加const)
04. 增加内联函数
05. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
06. 优化ROI形态学处理,对roi形态学处理添加红蓝色分类,消除灯条灯光影响
07. 尝试将deltaCV加入工程
08. 如何从源头将图片变小
09. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
10. （长期任务）优化形态学处理过程
11. 写角度结算文档
12. 优化初始图片形态学处理


2019/11/03 SUN

IDEA_NOTE
1. 由19年代码，帧率可以通过延时控制
2. en,确定了，深度学习的追踪算法在速度上就是垃圾，即使是号称可以达到100fps的goturn也是垃圾

BUG_NOTE


DONE
1. 由灰度图重制两份models
2. 调整ROI形态学处理（待改进）

TODO
01. 打算加入log系统
02. 为之前构造的类补充析构函数
03. (查找适当修改变量类型，提炼公共子表达式，减少参数传递,添加const)
04. 增加内联函数
05. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
06. 优化ROI形态学处理,对roi形态学处理添加红蓝色分类,消除灯条灯光影响(-ing)
07. 尝试将deltaCV加入工程
08. 如何从源头将图片变小
09. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
10. （长期任务）优化形态学处理过程
11. 写角度结算文档
12. 优化初始图片形态学处理


2019/11/04/MON

IDEA_NOTE
1. 由19年代码，帧率可以通过延时控制
2. 反其道而行，去除高亮部分(放弃，1.无法判断死活； 2.灯光干扰过大；不过思路可用以用在ROI形态学处理上)，直接findcontours，检测boundingrect/旋转矩形内检测筛选数字，矩形面积排除部分，ORB，cutleft()
3. 自适应阈值，canny边缘检测


BUG_NOTE


DONE
1. 结算文档大部分完成
2. 测试一部分边缘检测算法，效果不甚理想

TODO
01. 打算加入log系统
02. 为之前构造的类补充析构函数
03. (查找适当修改变量类型，提炼公共子表达式，减少参数传递,添加const)
04. 增加内联函数
05. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
06. 优化ROI形态学处理,对roi形态学处理添加红蓝色分类,消除灯条灯光影响(-ing)
07. 尝试将deltaCV加入工程
08. 如何从源头将图片变小
09. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
10. （长期任务）优化形态学处理过程
11. 写角度结算文档
12. 优化初始图片形态学处理


2019/11/05/TUE

IDEA_NOTE
针对SVM偶尔不能正确分类ROI的问题，原因是多方面的，可能是SVM本身的性能的限制，也有图片本身处理的原因，一个处理方法难以适用于所有的情况；因此打算设置一个阈值范围，对一个ROI进行多次阈值化，并多次用分类器验证，主要在跟踪区域内小范围的验证
,还可以加上原子操作，进行并行运算，加快检验速度。

DONE
1. 角度结算文档完成并提交

TODO
01. 打算加入log系统
02. 增加内联函数
03. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
04. 尝试将deltaCV加入工程
05. 如何从源头将图片变小
06. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
07. （长期任务）优化形态学处理过程


2019/11/06/WED

NOTE

使用阈值化，不管怎么样，总是会有光污染，影响轮廓的寻找，或者数字残缺不全
，考虑要不要对ROI的各通道的值加权重组

DONE

1.缺乏实质性进展，只完善了一下昨天的想法，并写出部分代码进行测试，但效果还不甚理想

TODO
01. 打算加入log系统
03. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
04. 尝试将deltaCV加入工程
05. 如何从源头将图片变小
06. 考虑测距能不能做到更好(视觉slam14里有讲PnP优化)
07. （长期任务）优化形态学处理过程


2019/11/07/THU

NOTE
鉴于这几天把19年代码复现完成没多久就开始没有思路，头绪混乱，不知道接下来该怎么走
，于是先理一下现状。

1.自瞄功能大体复现19年，再结合上交的启发加入了追踪器，当然效果不是很理想，
目前追踪器主要用来缩小下一帧的检测范围，功能类似于19年的区域加速，这又回到原本19年的思路上去了。

2.问题：对象跳动，跳动的原因有，击打过程中灯条熄灭，SVM分类器误分类，SVM误分类一方面是SVM自身的限制，另一方面
是对ROI形态学处理的问题

3.目前已有想法，将上一次识别到的目标（除工程外）设为最高优先级，并已经实现，但是当目标在视野范围内却检测不到这个对象时也只能
徒呼奈何；       对ROI进行多次不同的形态学处理（并行？）以适应不同环境，对分类结果取并集，减少灯条对装甲板分类的影响；
寻找新的效果更好的分类器     ； 因为灯条熄灭一般只出现一帧，因此在两帧（或者n帧）内没出现目标可以按照预测方位传递目标，防止频繁切换目标，两（n）帧后再开始SEARCHING_MODE，全局检测；
考虑能否使用传统全局检测后在ROI区域内进行深度学习检测;

4.再多参考几家的代码

DONE

没有。。。看了几家代码》》》了解了一下yolo和一些其他的深度检测器或者追踪器

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. 尝试将deltaCV加入工程
04. 如何从源头将图片变小
05. （长期任务）优化形态学处理过程


2019/11/08/FRI

NOTE
1. 对帧率进行分析，得出在画面中开始有灯条时帧率会明显降低，没有灯条时速率提升接近十倍，也就是说，灯条处理到得出结果过程出现了问题
,再对运行记录进行分析，发现即使没有匹配出灯条对，仅在判断灯条时就会耗时10ms以上，说明图像预处理不行，cv::findcontours()耗费了时间;
频繁调用SVM时，时间耗费达到了20ms，那么灯条对的匹配也需要优化
进一步分析，12ms耗时时10ms耗在装甲板寻找上，这10ms中会有5ms耗在灯条对的匹配上

DONE
1. 分析出帧率慢的原因

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. 尝试将deltaCV加入工程
04. 如何从源头将图片变小
05. （长期任务）优化形态学处理过程
06. 改善帧率

2019/11/09/SAT

NOTE
1. 发现resize的过程会耗费大量的时间，5ms左右
2. 计时发现相机线程完成预处理需要4ms（change_2）
3. 即使是相对来说最快的追踪算法MOSSE追踪一帧也需要7ms，不如检测来得快，打算放弃追踪而采用区域加速的思想，
因为战斗时，相对来说是拒不移动，区域加速只需要适当放大检测
区域，准确性不会低于追踪，且速度更快
4. 还有个问题，在进入单灯条模式后或者由加速模式进入全局检测后存在灯条重复验证的问题
5. 存在灯条对中夹杂着灯条的问题
6.想想如何让挨得近的灯条优先匹配(基于灯条高度排序后，优先与此灯条距离近的灯条匹配)
7. 在桌子两端对装甲板进行测试发现测距极其不准确，差异极大，明天来后需要查一下问题
8. 理论上说灯条从最近的开始匹配不应该存在灯条对内存在灯条的情况，可是似乎测试过程中缺失发现有这个问题

DONE
1. 优化预处理过程及添加大量内联函数，帧率在视频模式下勉强达到100FPS；
2. 将相机的输出图片尺寸改为640*512，取消resize，相机预处理时间由6ms变为4ms，但不知道会不会缩小视野范围
,en,试了下，视野缩小了,那么要怎么在采集分辨率不变的情况下设置输出分辨率呢。。。
3. 严格灯条匹配条件，帧率在摄像机模式下达到100FPS；但这其实还需要加上相机那边的处理时间，实际延时更高
4. 去掉算法追踪，改为在上次目标出现区域检测
5. 对灯条从大到小排序，灯条对匹配一旦匹配出成功一个非零，跳过一次匹配；
6. 灯条对匹配增加提前中止条件（检测出上次目标ID;非零ID>2;）,将非装甲板灯条对从vector中去除，可以考虑改灯条对类为装甲板类了，且
删除原装甲板类,删除匹配成功的后灯条，防止重复匹配
7. 帧率有了一个不错的提升，但是死等又是一个问题
8. 用了deltaCV的inrange代替OpenCV的inrange，。。。效果感觉不是十分明显

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. 如何从源头将图片变小(焦距变小？)
04. （长期任务）优化形态学处理过程
05. 查找SolvePnP错误
06. 考虑死等问题


2019/11/10/SUN

NOTE
1. SolvePnP之前问题是，将前两个坐标点颠倒了，故导致之前的效果不准确，还需要测试
2. 考虑昨晚上的远距离目标跳动的问题，应当是对图像的预处理没有优化好，灯条对无法正常匹配，灯条长度变化，启用了虚拟灯条，
一会会先匹配一个灯条，而一会就可能先匹配另一个，而上一帧目标没能在本帧被发现，就会开始目标跳动//或者一个装甲无需单灯条，而另一个
需要开启单灯条，那么可以考虑改变单灯条条件，即没发现上一帧目标也开启单灯条，单灯条只匹配那些没有匹配成功的灯条
3.为了更好地发现上一帧目标，需设计一个标识符来记录未进行单灯条匹配时是否发现上一帧目标，默认为false，一旦发现为true
5. 有的时候一个目标偶尔会被遮挡，这种时候，很容易切换目标，是否考虑添加要在经过固定帧数后没能发现那一个目标后才切换目标

但是在此期间容易可能会乱跳目标（这几帧一直没有发现保存的LastID时），是否设置一个临时追踪目标作为过渡？考虑中

6. 发现DeltaCV的inrange函数在分割HSV图片时并没有CV::inrange快（5ms），其他情况或者加权灰度化没试过


DONE
1/2. 见note
2. 调试时偏转过大，认为是发射角过大的问题，但后面这么想感觉不太对劲，因为我和去年的代码发送的值是一致的，我多除二，反而导致
传出去的数值不同，当然也能到达目标，毕竟本身就是个不断接近的过程，这样反而更平滑，但是终究和预想的不一样，还需要再理一下思路

TODO
01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. 如何从源头将图片变小(焦距变小？)
04. （长期任务）优化形态学处理过程
05. 考虑死等问题
06 .solvePnP问题

2019/11/11/MON

NOTE

因为图像被压缩了1/2，分辨率减少为原来的1/2；但相机的内参对应的是图像原本获取的图片的，因此在解算物体在相机坐标系中的坐标时，
需要将对应的像素坐标target*=2;从这个角度来说从源头把图片变小似乎是不可行的，焦距不变，那么实际图片对应成的像的尺寸不会变，
这是由相机内参数决定好的，想要压缩只有在获取图片后再处理，那么和opencv的resize意义是一样的，都需要耗时，唯一可以的优化是，将
这个过程放在需要等待另一个线程的线程中进行。

逻辑问题

DONE
1. 修正灯条匹配过程的逻辑问题

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05 .solvePnP问题

2019/11/12TUE

NOTE
1. 发现灯条匹配条件之错位条件似乎造成了比较严重的漏识别，需要继续研究是那个条件细节出了问题
2. （1）区分敌我可以在进行预处理将我方颜色去除掉；（2）对灯条处理时判断是敌是友(频繁调用处理应该会标耗时，不如在与处理时直接去掉)

DONE

1. 添加灯条匹配细节，防止两灯条中间包含有灯条时继续匹配，减少调用SVM，加快匹配时间
2. 虽然实际上两灯条符合错位条件但拟合椭圆的高度就是有问题，因此要适当地放宽条件,放宽了条件

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05 .solvePnP问题
06 .延时控制

2019/11/13/WED

NOTE
1. 突然想到,为什么不使用轮廓点的颜色来判断呢？我可真蠢

TARGET

1. 距离，足够远的距离发现对方，先发制人
2. 稳定的帧率，稳定的目标锁定，不受附近车辆的干扰，不受背景灯光的干扰，保证云台的稳定性
3. 实时性，处理够快，尽可能快地找到预想目标
4. 受操作手控制，能击打操作手希望打中的目标



DONE
1. 加入敌我判断，效果良好，且基本没对帧速造成影响（采用采取灯条两端点RB分量均值再比较大小的方法，在我方为red时静止时偶尔会有一两帧误判，不会造成影响）
2. 延时控制

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05 .solvePnP问题


2019/11/14/THU

NOTE
1. 关于操作手希望指哪打哪有两个思路：1) 当操作手发现在当前目标外由更希望击打的目标后，由操作手传回一个数字，指定其希望目前希望击打的目标，
接下n帧将会将此目标设为最高优先级，一旦程序在视野内发现目标，立即锁定此目标； 2）在视野范围內划定一块最高优先级范围，由操作手将云台移动，将此目标拉入
距屏幕中央一定范围内，此时将其设为最高优先级

第二思路实现起来比第一个难啊，而且，一旦视野内有多个目标纠缠在一起时，操作手很难操作，以为可能会将多个目标放入范围内，如果按最近距离来，那么就会
打乱其他的既定优先级

稳定的帧率需要一个稳定的下限帧率

2. OpenCV里的GPU加速能不能使用呢

TARGET

1. 距离，足够远的距离发现对方，先发制人
2. 稳定的帧率，稳定的目标锁定，不受附近车辆的干扰，不受背景灯光的干扰，保证云台的稳定性
3. 实时性，处理够快，尽可能快地找到预想目标
4. 受操作手控制，能击打操作手希望打中的目标


DONE
1. solvePnP测距不准确的问题解决,像素坐标系忘记还原

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程


2019/11/15/FRI

TARGET

1. 距离，足够远的距离发现对方，先发制人
2. 稳定的帧率，稳定的目标锁定，不受附近车辆的干扰，不受背景灯光的干扰，保证云台的稳定性
3. 实时性，处理够快，尽可能快地找到预想目标
4. 受操作手控制，能击打操作手希望打中的目标


NOTE

DONE

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程
07. 考虑偏离目标问题

11/16-11/19
全面复习空窗期，未做

2019/11/19/TUE

云台上下15:-20度;左右自由360

NOTE

1. 关于决策，之前和石总讨论，可以将在屏幕某个范围内目标设为最高优先级(因为操作手可以选择是否开启自瞄)，那么对灯条的排序方式也需要改变，
谁离屏幕中心近谁先开始匹配
2. 拓展装甲板，根据一块装甲板的灯条来推测相邻装甲板的位置,单灯条可以沿两个方向进行推测，一个是水平方向，另一个是倾斜角方向
3. 将SVM做成二分类以加快分类速度，但是这样追踪上一帧目标为最高优先级的作用会失效，不能保证状态的稳定
4. 匹配单灯条时能否不限定一个值，而是一系列值以适应不同情况
5. 拓展装甲板的情况似乎有点多，一一调用SVM验证会耗费大量的时间,不加进去

DONE

1. 更改优先级排列方式,可能会便于操作手的控制并减少视野的突然改变即视野剧烈晃动
2. 添加虚拟装甲板沿水平方向进行推测

TODO


2019/11/20/WED

DONE

1. finish one test


2019/11/21/THU

NOTE
1. 和毛影学长交流得到可以对哨兵使用追踪算法的想法


DONE

1. finish the second test,if the distance smaller than 0.5 m,the AutoHit could not find the target continully;the reason
may be that the conditions of the bar-match have some problems.
2. fix the color-judge bugs
3. fix the blob-judge(angle) bugs


TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程
07. 考虑偏离目标问题
08. 改变排除灯条方式，由斜率改为角度
09. 一NUC二相机


2019/11/22/FRI

DONE

1.修复PnP结算出距离始终为0的问题（原因：精度隐式转换）

2019/11/23/SAT

DONE

NOTHING


2019/11/24/SUN

NOTE

1.  突然出现时晃动很大
2. 近距离范围较窄


DONE

1. 进行第三次调试，

TODO

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程
07. 考虑偏离目标问题
08. 改变排除灯条方式，由斜率改为角度
09. 一NUC二相机

2019/11/25-2019/11/27 Mon-Wed

DONE

1. 整体结构大改，将所有功能封装成类
2. 完成一NUC带动双相机工作（目前主要采用双进程，C++11的并发编程无法imshow难以调试，且双线程同时启动时会出现内存问题，
故弃用）
3. 完成部分联调，我这边还需要解决分类器不给力的问题

11/28-12/1 THU-SUN

DONE
1. 联调,老问题解决，抖动疯转未解决
2. 尝试换分类器，仍未成功，很多参数都不明白，darknet训练出的模型不能用其余尚无成果

TODO（短期）

1. 分类器
2. 测试双进程通信
3. 斜率-角度


TODO(长期)

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程

2019/12/02 MON

DONE

1. 了解了一些tensorflow的基础

TODO（短期）

1. 分类器
2. 测试双进程通信
3. 斜率-角度


TODO(长期)

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程

2019/12/03 TUE

NOTE

1. 今天只用串口线进行双相机的通信测试时，并没有报错，不明白为什么那天为什么在车上会报错，晚上在邬豪杰车上试试
2. 串口通信搞定，忘记删除残留的字符
3.

2019/12/04 WED

DONE

1.完成PnP测试，正对情况较为理想，一旦稍微倾斜，误差较大，特别是距离较大的情况下难以精确，会跳动地特别厉害

2019/12/05 THU

NOTE

1. 关于预测：将装甲板的出现视为一个锯齿波模型，云台固定不动，在装甲板在边缘出现时推测云台将要达到中间的时间，定时发出打击指令
2. 将预测放在世界坐标系中进行，需要电控返回相机位姿信息，但可能不精确，需要一个处理

DONE

1. 将仝硕的训练集加入我的模型
2.

TODO（短期）

1. 分类器
2. 测试双进程通信
3. 斜率-角度
4. 参数调节，目前我的参数过于严苛，取消了一部分条件，帧率大降


TODO(长期)

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程



2019/12/07 SAT

NOTE

1. 考虑再次讲追踪加回去，并且针对追踪模式单独再做一套训练集，用那种比较粗糙图片来做，舍弃部分精度来换取大部分时候的连续性，再查查关于追踪算法的资料，是否有一些参数没有设置到位。
2. 和邬豪杰，阿吉交流了一下，陀螺角度应该可以通过红外传感器测出来，有了角度，那么就应该可以对准自旋中心，就可以计算速度，推测接下来的运动状态，从而确定击打陀螺的时间。

2019/12/09 MON

DONE
1. 完成部分参数修改，inrange阈值修改为五十，解决部分灯条的误判


TODO（短期）

1. 分类器
2. 测试双进程通信
3. 斜率-角度
4. 参数调节，目前我的参数过于严苛，取消了一部分条件，帧率大降


TODO(长期)

01. 打算加入log系统
02. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
03. （长期任务）优化形态学处理过程
04. 考虑死等问题
05. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
06. 学习SIMD库，加速处理过程

2019/12/10 TUE

DONE
1. 加入log系统

TODO（短期）

1. 分类器
2. 斜率-角度


TODO(长期)

01. 具体了解从cFrame->cv::Mat转换过程，图片数据储存格式
02. （长期任务）优化形态学处理过程
03. 考虑死等问题
04. 将部分函数测试cv::cuda::gpu加速版本，为tx2做一下准备
05. 学习SIMD库，加速处理过程


2019/12/11 WED

DONE

1. 添加视频录制
2. 再添加了一部分训练集，远距离效果改良，制作省赛专版三分类SVM模型

2019/12/12 THU

DONE

1. 完成自启动与退出重启
2. 视频录制与log完善

2019/12/13 - 2019/12/15

DONE

1. 配置两台NUC
2. 一台NUC有问题，可能是不能正常散热，另再发现一摄像头有问题
3. archlinux真难用


2020/01/13 MON

DONE
1. 彻底完成模式切换
2.
TODO
１．接下来全身心完成分类器制作
２．将整个视觉改装成类

